---
title: OpenCV -1 # 제목
excerpt: # 서브 타이틀
date: 2023-03-17 09:30:00 +0900      # 작성일
lastmod: 2023-03-17 09:30:00 +0900   # 최종 수정일 : 구글 사이트등록 관련 필요
categories: Python         # 다수 카테고리에 포함 가능
tags: python opencv c c++ 파이썬 영상 이미지 처리                     # 태그 복수개 가능
classes:         # wide : 넓은 레이아웃 / 빈칸 : 기본 //// wide 시에는 sticky toc 불가
toc: true        # 목차 표시 여부
toc_label:       # toc 제목
toc_sticky: true # 이동하는 목차 표시 여부 (toc:true 필요) // wide 시에는 sticky toc 불가
header: 
  image:         # 헤더 이미지 (asset내 혹은 url)
  teaser:        # 티저 이미지??
  overlay_image:             # 헤더 이미지 (제목과 겹치게)
  overlay_color: "#333"            # 헤더 배경색 (제목과 겹치게) #333 : 짙은 회색
  video:
    id:                      # 영상 ID (URL 뒷부분)
    provider:                # youtube, vimeo 등
sitemap :                    # 구글 크롤링
  changefreq : daily         # 구글 크롤링
  priority : 1.0             # 구글 크롤링
author: # 주인 외 작성자 표기 필요시
---
<!--postNo: 20230317_001-->

# OpenCV  


<br>
<br>
<br>

# OpenCV 설치  

여러 설치 방법이 있으며, 자신에게 맞는 설치 방법을 선택하면 된다.  
이 포스트에서는 Conda 로 설치해 진행한다.  

* Github : [https://github.com/opencv/opencv/releases](https://github.com/opencv/opencv/releases)  
* SourceForge : [https://sourceforge.net/projects/opencvlibrary/files/](https://sourceforge.net/projects/opencvlibrary/files/)  
* Linux 판 : [https://pkgs.org/search/?q=opencv](https://pkgs.org/search/?q=opencv)  
* Pypi : [https://pypi.org/search/?q=opencv](https://pypi.org/search/?q=opencv)  
* Conda : [https://anaconda.org/search?q=opencv](https://anaconda.org/search?q=opencv)  
* Java eclipse : [https://docs.opencv2.org/4.x/d1/d0a/tutorial_java_eclipse.html](https://docs.opencv2.org/4.x/d1/d0a/tutorial_java_eclipse.html)  
* 안드로이드 : [https://docs.opencv2.org/4.x/d7/dbd/tutorial_android_ocl_intro.html](https://docs.opencv2.org/4.x/d7/dbd/tutorial_android_ocl_intro.html)  


```python

conda install opencv

```

<br>
<br>
<br>

# 핵심 기능 The Core Functionality  

<br>
<br>

## Mat - The Basic Image Container  

<br>
<br>

## Open CV로 이미지 스캔, 조회 테이블, 시간 측정 스캔  

<br>
<br>

## Mask operations on matrices  

<br>
<br>

## 이미지 작업 Operations with images 

<br>

### 이미지 입출력  

```python
# OpenCV 라이브러리 import
import cv2

# 이미지 경로 선언
path = 'path/of/imagefile.extension'

# 이미지 불러오기 : 3채널 컬러 이미지
img_rgb = cv2.imread(path)

# 이미지 불러오기 : 그레이 스케일
img_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # 방법 1
img_gray = cv2.imread(path, 0)                   # 방법 2
```

<br>

### 이미지 보기  

```python
# 이미지 보기
import cv2

path = 'path/of/imagefile.extension'
img_rgb = cv2.imread(path)
img_gray = cv2.imread(path, 0)

cv2.imshow('컬러 이미지', img_rgb)
cv2.waitKey()

cv2.imshow('그레이 이미지', img_gray)
cv2.waitKey()
```

위 코드를 실행하면 컬러 이미지와 그레이 이미지가  
각각 새로운 윈도우에서 보여진다.  

`cv2.waitKey()` 메서드는 사용자가 키(키보드) 입력을 기다리는 메서드이다. 인터프리터가 해당 메서드를 만나면 사용자의 키 입력을 기다렸다가, 키가 입력되면 다음 코드를 실행하게 된다.
{: .notice}

![](/assets/images/20230317_001_001.jpg)


### 이미지 저장  

```python
# 이미지 저장
import cv2
import numpy as np

# 랜덤int 500 x 500 픽셀 3channel RGB ndarray생성
img = np.random.randint(0, 256, size=(500, 500, 3), dtype=np.uint8)

# 이미지 보기
cv2.imshow('img', img)
cv2.waitKey()

# 이미지 저장
cv2.imwrite('/Users/jongya/Desktop/example.png', img) # png로 저장
cv2.imwrite('/Users/jongya/Desktop/example.jpg', img) # jpg로 저장
```

![](/assets/images/20230317_001_002.jpg)  
![](/assets/images/20230317_001_003.jpg)

### 픽셀 강도(intensity) 제어  

픽셀이란, 이미지을 이루는 가장 작은 단위인 사각형의 점을 뜻한다.  
이 픽셀에는 빨간색, 초록색, 파란색 등 색 정보가 담겨있다. (그레이스케일은 명암 정도만)  

위에서 만든 랜덤 이미지에서 [100, 100] 픽셀의 색 정보를 불러와보겠다.  

```python
# pixel intensity 보기
import cv2
import numpy as np

# 랜덤 이미지 만들기
img = np.random.randint(0, 256, size=(500, 500, 3), dtype=np.uint8)
cv2.imshow('img', img)
cv2.waitKey()

# 이미지의 특정 픽셀 값 출력
# _intensity = img[y, x]
_intensity = img[100, 100]
print(_intensity)

==> [202 226 1]
```
[100, 100] 픽셀의 색상은 [202, 226, 1] 임을 알 수 있다.  
이 색상이 무엇인지 알아보기 위해, [202, 226, 1] 이라는 색상으로 채운 500x500 픽셀을 만들어보겠다.  

```python
import numpy as np
import cv2

img = np.ones((500, 500, 3), dtype=np.uint8) * np.array([202, 226, 1], dtype=np.uint8)

cv2.imshow('img', img)
cv2.waitKey()
```

이 코드에서는 500x500x3channel shape의 ndarray를 만든 후, 각 값을 [202, 226, 1]로 설정을 해주었다.  
만들어진 이미지는 아래와 같다.  

![](/assets/images/20230317_001_004.jpg)

### 픽셀 강도 (intensity)  

픽셀의 강도는 [b, g, r] 식으로 출력됨을 볼 수 있다.  
이는 순서대로 색의 3원색인 Blue, Green, Red 를 뜻한다.  

우리는 평소에 3원색을 RGB라고 표현한다.  
그런데 왜 cv에서는 RGB가 아닌 BGR의 순서를 사용할까?  

바로, 픽셀 강도 값을 불러올 때 리스트의 마지막 값부터 빼오기 때문이다. 아래의 예시를 참고해보자.  

|픽셀 강도|--읽어들임-->|읽어들인 값|
|---|---|---|
|[B, G, R]|-->|[]|
|[B, G]|-->|[R]|
|[B]|-->|[R, G]|
|[]|-->|[R, G, B]|

즉, 픽셀 강도가 B, G, R 순서로 되어있어야 읽어들였을 때 RGB의 순서가 될 수 있는 것이다.  

```python
import numpy as np
import cv2

img = cv2.imread('/path/of/img.jpg')

print("100, 100 픽셀의 Blue 값  : ", img[100, 100, 0])
print("100, 100 픽셀의 Green 값 : ", img[100, 100, 1])
print("100, 100 픽셀의 Red 값   : ", img[100, 100, 2])

# 출력
# 100, 100 픽셀의 Blue 값  :  202
# 100, 100 픽셀의 Green 값 :  226
# 100, 100 픽셀의 Red 값   :  0
```

### 픽셀 강도 제어

픽셀 강도를 제어하는 방법은 여러 가지가 있으며, 아래를 참고한다.  

```python
import numpy as np
import cv2

img = cv2.imread('/Users/jongya/Desktop/ttt.jpg')

_intensity = img[100, 100]
print("변경 전 color 값 : ", _intensity)

# 3channel 값 모두 변경
img[100, 100] = 150
_intensity = img[100, 100]
print("변경 후-1 color 값 : ", _intensity)

# 3channel 값 각각 변경
img[100, 100] = [100, 150, 200]
_intensity = img[100, 100]
print("변경 후-2 color 값 : ", _intensity)

# Blue 값만 변경
img[100, 100, 0] = 0
_intensity = img[100, 100]
print("변경 후-3 color 값 : ", _intensity)

# Green 값만 변경
img[100, 100, 1] = 10
_intensity = img[100, 100]
print("변경 후-4 color 값 : ", _intensity)

# Red 값만 변경
img[100, 100, 2] = 30
_intensity = img[100, 100]
print("변경 후-5 color 값 : ", _intensity)

# 출력
# 변경 전 color 값 :  [202 226   0]
# 변경 후-1 color 값 :  [150 150 150]
# 변경 후-2 color 값 :  [100 150 200]
# 변경 후-3 color 값 :  [  0 150 200]
# 변경 후-3 color 값 :  [  0  10 200]
# 변경 후-3 color 값 :  [ 0 10 30]
```

### 픽셀 좌표

픽셀의 위치값은 [y, x] 좌표로 표시된다.  
즉, 세로축을 뜻하는 y가 먼저, 그 다음 가로축을 뜻하는 x값이 들어가게 된다.  
이는 cv에서 다루는 img가 ndarray 형태라는 것을 생각하면 쉽게 이해가 될 것이다.  

아래 예시에서는 500 x 500 픽셀 이미지를 4등분하여, 좌측 상단부터 Blue, Green, Red, Black 을 표시해보았다.  

```python
import cv2
import numpy as np

img = np.ones((500, 500, 3), dtype=np.uint8)

for y, row in enumerate(img):
    for x, pixel in enumerate(row):
        if (y<250)&(x<250):
            img[y, x] = [255, 0, 0] # Blue
        elif (y<250)&(x>=250):
            img[y, x] = [0, 255, 0] # Green
        elif (y>=250)&(x<250):
            img[y, x] = [0, 0, 255] # Red
        else:
            img[y, x] = [0, 0, 0]   # Black
            
cv2.imshow('img', img)
cv2.waitKey()
cv2.destroyAllWindows()
```

![](/assets/images/20230317_001_005.jpg)

### 이미지의 복사

cv에서는 img의 값을 ndarray로 표시한다.  
따라서 이미지의 복사는 numpy.copy() 메서드를 이용한다.  

이 때에는 deepcopy가 되기 때문에 각각은 다른 주소값을 가지게 된다.  

```python
import cv2
import numpy as np

# 위에서 만든 4color 이미지를 불러오고
img = cv2.imread('./4color.jpg')

# img_copy 변수에 이를 복사한 뒤,
# 복사 후 검은색으로 변경한다.
img_copy = np.copy(img)
img_copy[:] = 0

cv2.imshow('img', img)
cv2.waitKey()

cv2.imshow('img_copy', img_copy)
cv2.waitKey()
```

![](/assets/images/20230317_001_006.jpg)

### greyscale 로 변경

cv2.cvtColor 메서드와 cv2.COLOR_BGR2GRAY 옵션을 통해 이미지를 greyscale 로 변경할 수 있다.  

```python
import cv2
import numpy as np

# 위에서 만든 4color 이미지를 불러오고
img = cv2.imread('./4color.jpg')

# greyscale로 변경
img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 검은색으로 변경
img_black = np.copy(img)
img_black[:] = 0

cv2.imshow('img', img)
cv2.imshow('img_grey', img_grey)
cv2.imshow('img_black', img_black)
```

![](/assets/images/20230317_001_007.jpg)

### 이미지 값 유형 : 8UC1, 32FC1

이미지 픽셀 강도는 8UC1 와 32FC1 두 유형이 있다.  

8UC1 는 8비트 int값 즉, 픽셀 강도를 정수 값 0~255 범위로 나타낸다. 이를 다시 말하면 색상을 각각 256개의 강도로 나누어 표현이 가능하다는 것이다.  

32FC1 는 32비트 float값 즉, 픽셀 강도를 부동 소수점 값 0.0 ~ 1.0 범위로 나타낸다. 표현할 수 있는 값의 종류가 8UIC보다 많기 때문에 더욱 정밀한 색 표현이 가능하다.  

|항목|8UC1|32FC1|
|---|---|---|
|자료형|np.uint8 정수형|np.float32 부동소수점|
|값 범위|0 ~ 255|0.0 ~ 1.0|
|표현할 수 있는 값 종류|256가지|3.4 * 10^38 가지|
||기본적인 시각화 작업에 유용|사실상 무한대 표현(사람이 구별할 수 있는 색상을 넘어섬)|
|비고|부드러운 그래디언트 표현 제한적|부드러운 그래디언트 표현 가능|

이해를 돕기 위해 아래와 같이 예시 그림을 그려봤다.  
단, 정확한 표현이 아닌, 개념적인 표현임을 명심하자.  

![](/assets/images/20230317_001_008.jpg)

### 이미지 값 유형 변경

8UC1 과 32FC1 간의 변경은 아래와 같이 가능하다.  

먼저, uint8로 만든 8UC1 gradient image 를 32FC1 으로 변경하는 예시.    

```python
import numpy as np
import cv2

img_8UC1 = np.zeros((500, 500, 3), dtype=np.uint8)

for i in range(500):
    for j in range(500):
        img_8UC1[i,j] = [i//2, j//2, (i+j)//4]

img_32FC1 = img_8UC1.astype(np.float32)/255.0
```

![](/assets/images/20230317_001_009.jpg)


다음은 float32로 만든 32FC1 gradient image 를 8UC1 으로 변경하는 예시.

```python
import numpy as np
import cv2

img_32FC1 = np.zeros((500, 500, 3), dtype=np.float32)
for i in range(500):
    for j in range(500):
        img_32FC1[i,j] = [i/500, j/500, (i+j)/500]

img_8UC1 = cv2.convertScaleAbs(img, alpha=255)
# img_32FC1 = img * 255
```

![](/assets/images/20230317_001_010.jpg)

### Blending  

블렌딩은 두 이미지를 혼합하는 것을 말한다.  
맛있는 크로칸슈 JPG 이미지와, 투명 배경에 'Croquant Chou' 라는 텍스트가 있는 PNG 이미지를 합쳐보겠다.  

(1) OpenCV의 addWeighted 메서드를 이용하는 방법  
(2) numpy 에서 직접 계산하는 방법  

```python
# (1) OpenCV의 메서드를 이용하는 방법
import cv2
import numpy as np

src1 = cv2.imread('/path/to/croquant_img.jpg')
src2 = cv2.imread('/path/to/croquant_txt.png')

alpha = 0.5
beta = 1 - alpha
# alpha : blending 시 첫 이미지를 살릴 비율
# beta : blending 시 두 번째 이미지를 살릴 비율
# alpha + beta = 1.0

dst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)
```

```python
# (2) numpy 에서 직접 blending
import cv2
import numpy as np

src1 = cv2.imread('/path/to/croquant_img.jpg')
src2 = cv2.imread('/path/to/croquant_txt.png')

alpha = 0.5
beta = 1 - alpha

dst = np.uint8((alpha * src1) + (beta * src2))
```

![](/assets/images/20230317_001_011.jpg)


addWeighted 메서드의 γ(감마) 값을 조절하면 이미지 전체의 밝기를 조절할 수 있다.  

```python
import cv2
import numpy as np

src1 = cv2.imread('/Users/jongya/Desktop/img_rgb.jpg')
src2 = cv2.imread('/Users/jongya/Desktop/croq_text.png')

alpha = 0.5
beta = 1 - alpha

dst_1 = cv2.addWeighted(src1, alpha, src2, beta, -255.0)
dst_2 = cv2.addWeighted(src1, alpha, src2, beta, -150.0)
dst_3 = cv2.addWeighted(src1, alpha, src2, beta, -50.0)
dst_4 = cv2.addWeighted(src1, alpha, src2, beta, 0.0)
dst_5 = cv2.addWeighted(src1, alpha, src2, beta, 50.0)
dst_6 = cv2.addWeighted(src1, alpha, src2, beta, 150.0)
dst_7 = cv2.addWeighted(src1, alpha, src2, beta, 255.0)
```

![](/assets/images/20230317_001_012.jpg)

### Contrast and Brightness

이미지의 대비와 밝기를 조절하는 방법을 기술한다.  
우선, 기본적인 대비와 밝기 조절의 원리는 아래와 같다.

```python

new_img = (alpha * img) + beta

# alpha : 밝기 조절. intensity 에 곱하기
# beta  : 대비 조절. intensity 에 더하기
# img   : ndarray 형태

```

여기에 numpy의 clip 메서드를 적용하여 ndarray의 최소값과 최대값을 제한해준다.

```python
import numpy as np

new_img = np.clip((alpha * img) + beta, min_v, max_v)

# np.clip
# ndarray 내의 원소값들에 대해
# min 값보다 작은 값들은 min 값으로 바꿔주고
# max 값보다 큰 값들은 max 값으로 바꿔준다.

```

원리는 픽셀의 intensity를 곱하거나 더해서 값을 조절하는 것이다.  

대비 조절은 곱하기를 통해, 그리고 밝기 조절은 더하기를 통해 조절이 된다. 즉, 원리는 동일한 것. 다만, 값을 증감시키는 방식이 곱하기냐 더하기냐에 따라 달라진다.  

원래 값이 작다면 곱하기를 통해 변경되는 값의 폭은 적고, 원래 값이 크다면 곱학를 통해 변경되는 값의 폭은 크게 된다. 하지만 더하기는 원래 값이 작든 크든 연산을 통한 변경 값의 폭은 동일하다.  

다음은 ndarray의 연산 방법을 살펴보자.  

이미지의 ndarray의 자료형태는 np.uint8로, 기본적으로 2^8개인 256개의 값을 표현할 수 있다.  

uint8 타입의 ndarray에 곱하기와 더하기 연산이 진행되면서 uint8이 표현할 수 있는 범위인 0 ~ 255 을 벗어나면 랩어라운드(Wrap around) 가 일어나면서 255를 초과하는 값만이 표시된다.  

여기에 np.clip을 타입 지정하기 전에 적용함을 통해 최대값과 최소값을 제한함으로써 astype을 통한 랩어라운드가 일어나기 전에 조정값이 소실되지 않게끔 한다. 자세한 것은 아래에서 예를 든다.  

```python
test = np.array([[[10, 20, 30], [40, 50, 60]],[[70, 80, 90], [100, 110, 120]]])

print(3 * test)
- [[[ 30,  60,  90],[120, 150, 180]],
- [[210, 240,  14],[ 44,  74, 104]]]
# 10은 30이 되지만
# 120은 360 - 256 = 104 가 된다.

print(test + 200)
- [[[210, 220, 230],[240, 250, 260]],
- [[ 270, 280, 290],[300, 310, 320]]]
# 곱하기와 달리 값이 잘리지 않음을 볼 수 있다.

print((test + 200).astype(uint8))
- [[[210, 220, 230],[240, 250,   4]],
- [[ 14,  24,  34],[ 44,  54,  64]]]
# uint8 타입으로 제한하면, 랩어라운드가 일어난다.
# 랩어라운드는 test를 선언할 때에 타입을 적용해도 일어난다.

print(np.clip(1.5 * test + 120), 0, 255)
- [[[135., 150., 165.],[180., 195., 210.]],
- [[225., 240., 255.],[255., 255., 255.]]]
# np.clip을 통해 uint8 범위를 벗어나는 값들은 모두
# 255라는 최대범위로 표현됨을 볼 수 있다.

```

실제 밝기와 대비 조절에 대한 예시는 아래와 같다.  

```python

import cv2
import numpy as np
import matplotlib.pyplot as plt

img_origin = cv2.imread('/Users/jongya/Desktop/img_rgb.jpg')

alpha = 1.0
beta = 0
min_v = 0
max_v = 255

img_after = np.clip(alpha * img_origin + beta, min_v, max_v).astype(np.uint8)

fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))
ax1.imshow(cv2.cvtColor(img_origin, cv2.COLOR_BGR2RGB))
ax1.set_title('Original Image')
ax2.imshow(cv2.cvtColor(img_after, cv2.COLOR_BGR2RGB))
ax2.set_title('Adjusted Image')
plt.show()

```

원본  
![](/assets/images/20230317_001_013.png)  
대비 증가  
![](/assets/images/20230317_001_014.png)  
대비 감소 + 밝기 증가
![](/assets/images/20230317_001_015.png)  
밝기 증가  
![](/assets/images/20230317_001_017.png)  
표현값(min, max) 제한  
![](/assets/images/20230317_001_018.png)  







## 이산 푸리에 변환 (DFT)

![](/assets/images/20230317_001_019.png)

푸리에 변환이란 시간이나 공간에 대한 함수를 주파수 성분으로 분해하는 변환을 이야기한다. 지난 수업들 중 음성 기술 수업에서 푸리에 변환을 통해 음성을 멜스펙토그램으로 변환하고, 이를 다시 복원하는 작업을 했었는데, 이미지에도 그러한 푸리에 변환을 적용할 수 있다.  

음성에서는 푸리에 변환을 통해 시간의 흐름에 따른 각 주파수대의 값을 쉽게 볼 수 있었고,  
이와 비슷하게 이미지에서는 푸리에 변환을 통해 각 픽셀의 밝기(intensity) 값의 변화를 변화를 쉽게 볼 수 있을 것이다.  

즉, 이미지에서의 푸리에 변환을 쉽게 말하자면 "픽셀의 강도(=밝기) 변화를 주파수로 변환하는 것" 이라고 말할 수 있겠다.  

음성을 푸리에 변환을 통해 멜스펙토그램으로 만들었을 때에는 그 위상을 잃는 문제가 있었다. 그리고 그 위상을 복원하는 게 바로 WaveGlow와 같은 Vocoder 즉, 음성 합성 모델이었다.  

이미지에서는 blue, green, red 값을 각각 분리할 수 있고, 이 각각에 대한 푸리에 변환 또한 가능하다. 이 때문에 음성과는 달리 이미지는 푸리에변환 한 뒤 다시 컬러 이미지로 복원하는 데 큰 문제가 없을 것으로 예상된다. 이 점도 아래에서 공부를 진행하면서 알아보도록 하겠다.  

* 음성 -> 멜스펙토그램 -> 음성  

![](/assets/images/20230317_001_021.png)  

* 이미지 -> 푸리에스펙트럼 -> 이미지  

![](/assets/images/20230317_001_020.png)  


### 채널 분리 (B, G, R)

이미지 밝기(intensity)에 대한 푸리에 변환을 진행할 때에는 이미지를 greyscale로 변환한 뒤 진행하게 된다.  greyscale로의 변환을 하는 이유는  

(1) greyscale로 변환하면 이미지가 단일 채널로 변경되면서 푸리에 변환을 쉽게 처리 할 수 있고,  
(2) 밝기에 대한 푸리에 변환에서는 Blue, Green, Red 색상정보가 목적을 달성하기 위해 필수적이지 않기 때문이다.  

하지만 바꿔 말하면 greyscale로 변환한 이미지는 단순히 픽셀의 밝기에 대한 값만을 가지고 있으며, 각 색상에 대한 분석은 어렵다고 할 수 있겠다.  

그러면 여기서 든 생각. 각 채널을 분리한다면, 각 색상에 대한 푸리에 변환과 이를 통한 분석이 가능하지 않을까?  

```python
# 이미지에서 특정 채널 값만을 가져오기
import cv2
import numpy as np

img = cv2.imread('/path/to/img.jpg')
img_green = []

for i, rows in enumerate(img):
    temp_green = []
    for j, pixel in enumerate(rows):
        temp_green.append(pixel[1])
        # blue : 0 / green : 1 / red : 2
    img_green.append(temp_green)
        
img_green = np.array(img_green).astype(np.uint8)
```

이렇게 하면 green intensity만을 가져올 수 있다.  
그리고, 각 채널값을 분리하는 기능을 cv2에서 제공함을 나중에야 알았다. (...)  

```python
# 이미지 각 채널 값 분리
import cv2

# Load image
img = cv2.imread('/path/to/img.jpg')

# Split the image into it's color channels
b, g, r = cv2.splot(img)
```

각 채널값을 추출한 이미지, 그리고 greyscale 이미지를 만든 예시를 아래에 첨부한다.  

이미지를 보면 각 color 별로 동일 픽셀간에 intensity가 다름을 볼 수 있다.  

이를 통해 각 채널값을 추출하면, 각 색상 채널별로 분석과 이미지 처리가 가능할 것임을 짐작할 수 있었다.  

![](/assets/images/20230317_001_022.png)  

![](/assets/images/20230317_001_023.png)

(두 번째 이미지에선 특정 채널값만 하얀색임을 볼 수 있다. 이는 해당 채널값의 intensity가 높으기 때문)  

### 푸리에 변환

그러면 본격적으로 이미지에 대한 푸리에 변환을 진행해본다.  
OpenCV에서 푸리에 변환은 cv.dft() 라는 메서드를 통해 손쉽게 접근할 수 있다.  






# 기타 참고  

## Pixel 픽셀




# Reference  

* 푸리에 변환 : https://ko.wikipedia.org/wiki/%ED%91%B8%EB%A6%AC%EC%97%90_%EB%B3%80%ED%99%98  
* 